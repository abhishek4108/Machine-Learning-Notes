<!doctype html><html><head><meta charset="utf-8">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/2.10.0/github-markdown.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js">
<link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
<link rel="stylesheet" href="https://gitcdn.xyz/repo/goessner/mdmath/master/css/texmath.css">
<link rel="stylesheet" href="https://gitcdn.xyz/repo/goessner/mdmath/master/css/vscode-texmath.css">

</head><body class="markdown-body">
<h1 id="logistic-regression-1" data-line="0" class="code-line">Logistic Regression</h1>
<br>
<!-- toc -->
<ul>
<li data-line="5" class="code-line"><a href="#logistic-regression">Logistic Regression</a>
<ul>
<li data-line="6" class="code-line"><a href="#what-is-a-logistic-regression">What is a logistic regression?</a></li>
<li data-line="7" class="code-line"><a href="#logistic-regression-predicts-probabilities">Logistic Regression Predicts Probabilities</a></li>
<li data-line="8" class="code-line"><a href="#learning-the-logistic-regression-model">Learning the Logistic Regression Model</a></li>
<li data-line="9" class="code-line"><a href="#types-of-logistic-regression">Types of Logistic Regression</a></li>
<li data-line="10" class="code-line"><a href="#performance-of-logistics-regression-model">Performance of Logistics Regression Model</a>
<ul>
<li data-line="11" class="code-line"><a href="#1-confusion-matrix">1. Confusion Matrix</a></li>
<li data-line="12" class="code-line"><a href="#2-roc-curve">2. ROC Curve</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- tocstop -->
<h2 id="what-is-a-logistic-regression-1" data-line="16" class="code-line">What is a logistic regression?</h2>
<p data-line="17" class="code-line">Logistic Regression is a classification algorithm. It is used to predict a binary outcome (1 / 0, Yes / No, True / False) given a set of independent variables.</p>
<p data-line="19" class="code-line">In simple words, it predicts the probability of occurrence of an event by fitting data to a logit function.</p>
<p data-line="21" class="code-line">Below is an example logistic regression equation:</p>
<p data-line="23" class="code-line">y = e^(b0 + b1 * x) / (1 + e^(b0 + b1 * x))</p>
<p data-line="25" class="code-line">Where y is the predicted output, b0 is the bias or intercept term and b1 is the coefficient for the single input value (x). Each column in your input data has an associated b coefficient (a constant real value) that must be learned from your training data</p>
<h2 id="logistic-regression-predicts-probabilities-1" data-line="27" class="code-line">Logistic Regression Predicts Probabilities</h2>
<p data-line="29" class="code-line">Logistic regression models the probability of the default class (e.g. the first class).</p>
<p data-line="31" class="code-line">we are modeling the probability that an input (X) belongs to the default class (Y=1), we can write this formally as:</p>
<p data-line="33" class="code-line">P(X) = P(Y=1|X)</p>
<p data-line="35" class="code-line">Logistic regression is a linear method, but the predictions are transformed using the logistic function.</p>
<p data-line="37" class="code-line">p(X) = e^(b0 + b1 * X) / (1 + e^(b0 + b1 * X))</p>
<p data-line="39" class="code-line">ln(p(X) / 1 – p(X)) = b0 + b1 * X</p>
<p data-line="41" class="code-line">Odds are calculated as a ratio of the probability of the event divided by the probability of not the event, e.g. 0.8/(1-0.8) which has the odds of 4. So we could instead write:</p>
<p data-line="43" class="code-line">ln(odds) = b0 + b1 * X</p>
<p data-line="45" class="code-line">Because the odds are log transformed, we call this left hand side the log-odds or the probit. We can move the exponent back to the right and write it as:</p>
<p data-line="47" class="code-line">odds = e^(b0 + b1 * X)</p>
<h2 id="learning-the-logistic-regression-model-1" data-line="49" class="code-line">Learning the Logistic Regression Model</h2>
<p data-line="51" class="code-line">The coefficients (Beta values b) of the logistic regression algorithm must be estimated from your training data. This is done using maximum-likelihood estimation.</p>
<p data-line="53" class="code-line">Maximum-likelihood estimation is a common learning algorithm used by a variety of machine learning algorithms, although it does make assumptions about the distribution of your data.</p>
<p data-line="55" class="code-line">The intuition for maximum-likelihood for logistic regression is that a search procedure seeks values for the coefficients (Beta values) that minimize the error in the probabilities predicted by the model to those in the data (e.g. probability of 1 if the data is the primary class)</p>
<h2 id="types-of-logistic-regression-1" data-line="57" class="code-line">Types of Logistic Regression</h2>
<ol>
<li data-line="59" class="code-line">Binary Logistic Regression
The categorical response has only two 2 possible outcomes. Example: Spam or Not</li>
<li data-line="61" class="code-line">Multinomial Logistic Regression
Three or more categories without ordering. Example: Predicting which food is preferred more (Veg, Non-Veg, Vegan)</li>
<li data-line="63" class="code-line">Ordinal Logistic Regression
Three or more categories with ordering. Example: Movie rating from 1 to 5</li>
</ol>
<h2 id="performance-of-logistics-regression-model-1" data-line="66" class="code-line">Performance of Logistics Regression Model</h2>
<h3 id="1-confusion-matrix-1" data-line="68" class="code-line">1. Confusion Matrix</h3>
<img src="images/confusionmatrix.png">
<p data-line="72" class="code-line">Accuracy =  (TP + TN) / (TP + FP + FN + TN)</p>
<p data-line="74" class="code-line">True Positive Rate = Sensitivity = Recall =  TP / (TP + FN)</p>
<p data-line="76" class="code-line">False Positive Rate = FP / (FP + TN)</p>
<p data-line="78" class="code-line">True Negative Rate = Specificity = TN / (TN + FP)</p>
<p data-line="80" class="code-line">Precision = TP / (TP + FP)</p>
<h3 id="2-roc-curve-1" data-line="82" class="code-line">2. ROC Curve</h3>
<p data-line="84" class="code-line">Receiver Operating Characteristic(ROC) summarizes the model’s performance by evaluating the trade offs between true positive rate (sensitivity) and false positive rate(1- specificity)</p>
<p data-line="86" class="code-line">The area under curve (AUC), referred to as index of accuracy(A) or concordance index, is a perfect performance metric for ROC curve. Higher the area under curve, better the prediction power of the model. Below is a sample ROC curve. The ROC of a perfect predictive model has TP equals 1 and FP equals 0. This curve will touch the top left corner of the graph.</p>
<img src="images/roc.png" width="50%" height="50%">

</body></html>